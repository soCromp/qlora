{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/sonia/miniconda3/envs/cleanllama/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda122.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.9\n",
      "CUDA SETUP: Detected CUDA version 122\n",
      "CUDA SETUP: Loading binary /home/sonia/miniconda3/envs/cleanllama/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda122.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonia/miniconda3/envs/cleanllama/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /home/sonia/miniconda3/envs/cleanllama did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/sonia/miniconda3/envs/cleanllama/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('https'), PosixPath('//debuginfod.ubuntu.com ')}\n",
      "  warn(msg)\n",
      "/home/sonia/miniconda3/envs/cleanllama/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/home/sonia/miniconda3/envs/cleanllama/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/home/sonia/miniconda3/envs/cleanllama/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from qlora import *\n",
    "\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "argdict = {\n",
    "  'model_name_or_path' : '/zoo/llama2/llama2-7b-hf',\n",
    "  'data_seed' : 42 ,\n",
    "  'dataloader_num_workers' : 1 ,\n",
    "  'group_by_length' : True,\n",
    "  'remove_unused_columns' : False ,\n",
    "  'lora_r' : 64 ,\n",
    "  'lora_alpha' : 16 ,\n",
    "  'lora_modules' : 'all' ,\n",
    "  'double_quant' : True,\n",
    "  'quant_type' : 'nf4' ,\n",
    "  'bf16' : True,\n",
    "  'bits' : 4 ,\n",
    "  'dataset' : './data/vanilla-adult.dat',\n",
    "  'dataset_format': 'input-output',\n",
    "  'source_max_len' : 60 ,\n",
    "  'target_max_len' : 60 ,\n",
    "  'seed' : 0\n",
    "}\n",
    "\n",
    "arglist = [f'--{k}={v}' for k,v in argdict.items()]\n",
    "\n",
    "hfparser = transformers.HfArgumentParser((\n",
    "    ModelArguments, DataArguments, TrainingArguments, GenerationArguments\n",
    "))\n",
    "model_args, data_args, training_args, generation_args  = hfparser.parse_args_into_dataclasses(args=arglist, return_remaining_strings=True)[:-1]\n",
    "training_args.generation_config = transformers.GenerationConfig(**vars(generation_args))\n",
    "args = argparse.Namespace(\n",
    "    **vars(model_args), **vars(data_args), **vars(training_args)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading base model /zoo/llama2/llama2-7b-hf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonia/miniconda3/envs/cleanllama/lib/python3.10/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:32<00:00, 16.42s/it]\n",
      "/home/sonia/miniconda3/envs/cleanllama/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding special tokens.\n",
      "adding LoRA modules...\n",
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir, completed_training = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = get_accelerate_model(args, checkpoint_dir)\n",
    "model.config.use_cache = False\n",
    "    \n",
    "print('loaded model')\n",
    "set_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "collator = data_module['data_collator']\n",
    "datatr = data_module['train_dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    **{k:v for k,v in data_module.items() if k != 'predict_dataset'},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<s>This person's age is 47 sex is Female and country is Outlying US(Guam USVI etc). Education level is Some-college occupation is Transport moving and income is under 50K age is 47 sex is Female and country is Outlying US(Guam US\",\n",
       " 'age is 47 sex is Female and country is Outlying US(Guam USVI etc). Education level is Some-college occupation is Transport moving and income is under 50K age is 47 sex is Female and country is Outlying US(Guam US']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode([[    1,  4013,  2022, 29915, 29879,  5046,   338, 29871, 29946, 29955,\n",
    "          7916,   338, 19361,   744,   322,  4234,   338,  4451,  5890,  3148,\n",
    "         29898,  9485,   314,  3148, 18118,  2992,   467, 13151,  3233,   338,\n",
    "          3834, 29899,  1054,  4424, 26818,   338, 15710,  8401,   322, 17869,\n",
    "           338,  1090, 29871, 29945, 29900, 29968,  5046,   338, 29871, 29946,\n",
    "         29955,  7916,   338, 19361,   744,   322,  4234,   338,  4451,  5890,\n",
    "          3148, 29898,  9485,   314,  3148],\n",
    "                  [  5046,   338, 29871, 29946, 29955,\n",
    "          7916,   338, 19361,   744,   322,  4234,   338,  4451,  5890,  3148,\n",
    "         29898,  9485,   314,  3148, 18118,  2992,   467, 13151,  3233,   338,\n",
    "          3834, 29899,  1054,  4424, 26818,   338, 15710,  8401,   322, 17869,\n",
    "           338,  1090, 29871, 29945, 29900, 29968,  5046,   338, 29871, 29946,\n",
    "         29955,  7916,   338, 19361,   744,   322,  4234,   338,  4451,  5890,\n",
    "          3148, 29898,  9485,   314,  3148]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    1,  4013,  2022, 29915, 29879,  5046,   338, 29871, 29946, 29955,\n",
      "          7916,   338, 19361,   744,   322,  4234,   338,  4451,  5890,  3148,\n",
      "         29898,  9485,   314,  3148, 18118,  2992,   467, 13151,  3233,   338,\n",
      "          3834, 29899,  1054,  4424, 26818,   338, 15710,  8401,   322, 17869,\n",
      "           338,  1090, 29871, 29945, 29900, 29968,  5046,   338, 29871, 29946,\n",
      "         29955,  7916,   338, 19361,   744,   322,  4234,   338,  4451,  5890,\n",
      "          3148, 29898,  9485,   314,  3148]]), 'attention_mask': tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  5046,   338, 29871, 29946, 29955,\n",
      "          7916,   338, 19361,   744,   322,  4234,   338,  4451,  5890,  3148,\n",
      "         29898,  9485,   314,  3148, 18118,  2992,   467, 13151,  3233,   338,\n",
      "          3834, 29899,  1054,  4424, 26818,   338, 15710,  8401,   322, 17869,\n",
      "           338,  1090, 29871, 29945, 29900, 29968,  5046,   338, 29871, 29946,\n",
      "         29955,  7916,   338, 19361,   744,   322,  4234,   338,  4451,  5890,\n",
      "          3148, 29898,  9485,   314,  3148]])}\n",
      "{'input_ids': tensor([[    1,  4013,  2022, 29915, 29879,  5046,   338, 29871, 29906, 29896,\n",
      "          7916,   338, 19361,   744,   322,  4234,   338,  3303,  3900, 29889,\n",
      "         13151,  3233,   338,  3834, 29899,  1054,  4424, 26818,   338,  6189,\n",
      "          1015,  8681,   312,   322, 17869,   338,  1090, 29871, 29945, 29900,\n",
      "         29968,  5046,   338, 29871, 29906, 29896,  7916,   338, 19361,   744,\n",
      "           322,  4234,   338,  3303,  3900, 29889, 13151,  3233,   338,  3834,\n",
      "         29899,  1054,  4424, 26818,   338]]), 'attention_mask': tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  5046,   338, 29871, 29906, 29896,\n",
      "          7916,   338, 19361,   744,   322,  4234,   338,  3303,  3900, 29889,\n",
      "         13151,  3233,   338,  3834, 29899,  1054,  4424, 26818,   338,  6189,\n",
      "          1015,  8681,   312,   322, 17869,   338,  1090, 29871, 29945, 29900,\n",
      "         29968,  5046,   338, 29871, 29906, 29896,  7916,   338, 19361,   744,\n",
      "           322,  4234,   338,  3303,  3900, 29889, 13151,  3233,   338,  3834,\n",
      "         29899,  1054,  4424, 26818,   338]])}\n",
      "{'input_ids': tensor([[    1,  4013,  2022, 29915, 29879,  5046,   338, 29871, 29941, 29896,\n",
      "          7916,   338, 27208,   322,  4234,   338,  1605,   262,   328,   328,\n",
      "         29987, 29911,   711,  4425, 29889, 13151,  3233,   338,  3834, 29899,\n",
      "          1054,  4424, 26818,   338,  6189,  1015,  8681,   312,   322, 17869,\n",
      "           338,  1090, 29871, 29945, 29900, 29968,  5046,   338, 29871, 29941,\n",
      "         29896,  7916,   338, 27208,   322,  4234,   338,  1605,   262,   328,\n",
      "           328, 29987, 29911,   711,  4425]]), 'attention_mask': tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  5046,   338, 29871, 29941, 29896,\n",
      "          7916,   338, 27208,   322,  4234,   338,  1605,   262,   328,   328,\n",
      "         29987, 29911,   711,  4425, 29889, 13151,  3233,   338,  3834, 29899,\n",
      "          1054,  4424, 26818,   338,  6189,  1015,  8681,   312,   322, 17869,\n",
      "           338,  1090, 29871, 29945, 29900, 29968,  5046,   338, 29871, 29941,\n",
      "         29896,  7916,   338, 27208,   322,  4234,   338,  1605,   262,   328,\n",
      "           328, 29987, 29911,   711,  4425]])}\n",
      "{'input_ids': tensor([[    1,  4013,  2022, 29915, 29879,  5046,   338, 29871, 29946, 29941,\n",
      "          7916,   338, 19361,   744,   322,  4234,   338,  3303,  3900, 29889,\n",
      "         13151,  3233,   338,  3834, 29899,  1054,  4424, 26818,   338,  6189,\n",
      "          1015,  8681,   312,   322, 17869,   338,  1090, 29871, 29945, 29900,\n",
      "         29968,  5046,   338, 29871, 29946, 29941,  7916,   338, 19361,   744,\n",
      "           322,  4234,   338,  3303,  3900, 29889, 13151,  3233,   338,  3834,\n",
      "         29899,  1054,  4424, 26818,   338]]), 'attention_mask': tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  5046,   338, 29871, 29946, 29941,\n",
      "          7916,   338, 19361,   744,   322,  4234,   338,  3303,  3900, 29889,\n",
      "         13151,  3233,   338,  3834, 29899,  1054,  4424, 26818,   338,  6189,\n",
      "          1015,  8681,   312,   322, 17869,   338,  1090, 29871, 29945, 29900,\n",
      "         29968,  5046,   338, 29871, 29946, 29941,  7916,   338, 19361,   744,\n",
      "           322,  4234,   338,  3303,  3900, 29889, 13151,  3233,   338,  3834,\n",
      "         29899,  1054,  4424, 26818,   338]])}\n",
      "{'input_ids': tensor([[    1,  4013,  2022, 29915, 29879,  5046,   338, 29871, 29941, 29929,\n",
      "          7916,   338, 19361,   744,   322,  4234,   338,  3303,  3900, 29889,\n",
      "         13151,  3233,   338,  3834, 29899,  1054,  4424, 26818,   338,  6189,\n",
      "          1015,  8681,   312,   322, 17869,   338,  1090, 29871, 29945, 29900,\n",
      "         29968,  5046,   338, 29871, 29941, 29929,  7916,   338, 19361,   744,\n",
      "           322,  4234,   338,  3303,  3900, 29889, 13151,  3233,   338,  3834,\n",
      "         29899,  1054,  4424, 26818,   338]]), 'attention_mask': tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  5046,   338, 29871, 29941, 29929,\n",
      "          7916,   338, 19361,   744,   322,  4234,   338,  3303,  3900, 29889,\n",
      "         13151,  3233,   338,  3834, 29899,  1054,  4424, 26818,   338,  6189,\n",
      "          1015,  8681,   312,   322, 17869,   338,  1090, 29871, 29945, 29900,\n",
      "         29968,  5046,   338, 29871, 29941, 29929,  7916,   338, 19361,   744,\n",
      "           322,  4234,   338,  3303,  3900, 29889, 13151,  3233,   338,  3834,\n",
      "         29899,  1054,  4424, 26818,   338]])}\n",
      "{'input_ids': tensor([[    1,  4013,  2022, 29915, 29879,  5046,   338, 29871, 29941, 29947,\n",
      "          7916,   338, 19361,   744,   322,  4234,   338,  3303,  3900, 29889,\n",
      "         13151,  3233,   338,  3834, 29899,  1054,  4424, 26818,   338, 15710,\n",
      "          8401,   322, 17869,   338,  1090, 29871, 29945, 29900, 29968,  5046,\n",
      "           338, 29871, 29941, 29947,  7916,   338, 19361,   744,   322,  4234,\n",
      "           338,  3303,  3900, 29889, 13151,  3233,   338,  3834, 29899,  1054,\n",
      "          4424, 26818,   338, 15710,  8401]]), 'attention_mask': tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  5046,   338, 29871, 29941, 29947,\n",
      "          7916,   338, 19361,   744,   322,  4234,   338,  3303,  3900, 29889,\n",
      "         13151,  3233,   338,  3834, 29899,  1054,  4424, 26818,   338, 15710,\n",
      "          8401,   322, 17869,   338,  1090, 29871, 29945, 29900, 29968,  5046,\n",
      "           338, 29871, 29941, 29947,  7916,   338, 19361,   744,   322,  4234,\n",
      "           338,  3303,  3900, 29889, 13151,  3233,   338,  3834, 29899,  1054,\n",
      "          4424, 26818,   338, 15710,  8401]])}\n",
      "{'input_ids': tensor([[    1,  4013,  2022, 29915, 29879,  5046,   338, 29871, 29906, 29947,\n",
      "          7916,   338, 19361,   744,   322,  4234,   338,  3303,  3900, 29889,\n",
      "         13151,  3233,   338,  3834, 29899,  1054,  4424, 26818,   338, 15710,\n",
      "          8401,   322, 17869,   338,  1090, 29871, 29945, 29900, 29968,  5046,\n",
      "           338, 29871, 29906, 29947,  7916,   338, 19361,   744,   322,  4234,\n",
      "           338,  3303,  3900, 29889, 13151,  3233,   338,  3834, 29899,  1054,\n",
      "          4424, 26818,   338, 15710,  8401]]), 'attention_mask': tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  5046,   338, 29871, 29906, 29947,\n",
      "          7916,   338, 19361,   744,   322,  4234,   338,  3303,  3900, 29889,\n",
      "         13151,  3233,   338,  3834, 29899,  1054,  4424, 26818,   338, 15710,\n",
      "          8401,   322, 17869,   338,  1090, 29871, 29945, 29900, 29968,  5046,\n",
      "           338, 29871, 29906, 29947,  7916,   338, 19361,   744,   322,  4234,\n",
      "           338,  3303,  3900, 29889, 13151,  3233,   338,  3834, 29899,  1054,\n",
      "          4424, 26818,   338, 15710,  8401]])}\n",
      "{'input_ids': tensor([[    1,  4013,  2022, 29915, 29879,  5046,   338, 29871, 29953, 29906,\n",
      "          7916,   338, 19361,   744,   322,  4234,   338,  3303,  3900, 29889,\n",
      "         13151,  3233,   338,  3834, 29899,  1054,  4424, 26818,   338, 23354,\n",
      "           292,  9427,   292,   322, 17869,   338,  1090, 29871, 29945, 29900,\n",
      "         29968,  5046,   338, 29871, 29953, 29906,  7916,   338, 19361,   744,\n",
      "           322,  4234,   338,  3303,  3900, 29889, 13151,  3233,   338,  3834,\n",
      "         29899,  1054,  4424, 26818,   338]]), 'attention_mask': tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  5046,   338, 29871, 29953, 29906,\n",
      "          7916,   338, 19361,   744,   322,  4234,   338,  3303,  3900, 29889,\n",
      "         13151,  3233,   338,  3834, 29899,  1054,  4424, 26818,   338, 23354,\n",
      "           292,  9427,   292,   322, 17869,   338,  1090, 29871, 29945, 29900,\n",
      "         29968,  5046,   338, 29871, 29953, 29906,  7916,   338, 19361,   744,\n",
      "           322,  4234,   338,  3303,  3900, 29889, 13151,  3233,   338,  3834,\n",
      "         29899,  1054,  4424, 26818,   338]])}\n",
      "{'input_ids': tensor([[    1,  4013,  2022, 29915, 29879,  5046,   338, 29871, 29945, 29896,\n",
      "          7916,   338, 19361,   744,   322,  4234,   338,  3303,  3900, 29889,\n",
      "         13151,  3233,   338,  3834, 29899,  1054,  4424, 26818,   338, 11080,\n",
      "          8455,   616,   322, 17869,   338,  1090, 29871, 29945, 29900, 29968,\n",
      "          5046,   338, 29871, 29945, 29896,  7916,   338, 19361,   744,   322,\n",
      "          4234,   338,  3303,  3900, 29889, 13151,  3233,   338,  3834, 29899,\n",
      "          1054,  4424, 26818,   338, 11080]]), 'attention_mask': tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  5046,   338, 29871, 29945, 29896,\n",
      "          7916,   338, 19361,   744,   322,  4234,   338,  3303,  3900, 29889,\n",
      "         13151,  3233,   338,  3834, 29899,  1054,  4424, 26818,   338, 11080,\n",
      "          8455,   616,   322, 17869,   338,  1090, 29871, 29945, 29900, 29968,\n",
      "          5046,   338, 29871, 29945, 29896,  7916,   338, 19361,   744,   322,\n",
      "          4234,   338,  3303,  3900, 29889, 13151,  3233,   338,  3834, 29899,\n",
      "          1054,  4424, 26818,   338, 11080]])}\n",
      "{'input_ids': tensor([[    1,  4013,  2022, 29915, 29879,  5046,   338, 29871, 29906, 29953,\n",
      "          7916,   338, 27208,   322,  4234,   338,  3303,  3900, 29889, 13151,\n",
      "          3233,   338,  3834, 29899,  1054,  4424, 26818,   338,  6189,  1015,\n",
      "          8681,   312,   322, 17869,   338,  1090, 29871, 29945, 29900, 29968,\n",
      "          5046,   338, 29871, 29906, 29953,  7916,   338, 27208,   322,  4234,\n",
      "           338,  3303,  3900, 29889, 13151,  3233,   338,  3834, 29899,  1054,\n",
      "          4424, 26818,   338,  6189,  1015]]), 'attention_mask': tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  5046,   338, 29871, 29906, 29953,\n",
      "          7916,   338, 27208,   322,  4234,   338,  3303,  3900, 29889, 13151,\n",
      "          3233,   338,  3834, 29899,  1054,  4424, 26818,   338,  6189,  1015,\n",
      "          8681,   312,   322, 17869,   338,  1090, 29871, 29945, 29900, 29968,\n",
      "          5046,   338, 29871, 29906, 29953,  7916,   338, 27208,   322,  4234,\n",
      "           338,  3303,  3900, 29889, 13151,  3233,   338,  3834, 29899,  1054,\n",
      "          4424, 26818,   338,  6189,  1015]])}\n",
      "{'input_ids': tensor([[    1,  4013,  2022, 29915, 29879,  5046,   338, 29871, 29945, 29896,\n",
      "          7916,   338, 27208,   322,  4234,   338,  3303,  3900, 29889, 13151,\n",
      "          3233,   338,  3834, 29899,  1054,  4424, 26818,   338,  6189,  1015,\n",
      "          8681,   312,   322, 17869,   338,  1090, 29871, 29945, 29900, 29968,\n",
      "          5046,   338, 29871, 29945, 29896,  7916,   338, 27208,   322,  4234,\n",
      "           338,  3303,  3900, 29889, 13151,  3233,   338,  3834, 29899,  1054,\n",
      "          4424, 26818,   338,  6189,  1015]]), 'attention_mask': tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  5046,   338, 29871, 29945, 29896,\n",
      "          7916,   338, 27208,   322,  4234,   338,  3303,  3900, 29889, 13151,\n",
      "          3233,   338,  3834, 29899,  1054,  4424, 26818,   338,  6189,  1015,\n",
      "          8681,   312,   322, 17869,   338,  1090, 29871, 29945, 29900, 29968,\n",
      "          5046,   338, 29871, 29945, 29896,  7916,   338, 27208,   322,  4234,\n",
      "           338,  3303,  3900, 29889, 13151,  3233,   338,  3834, 29899,  1054,\n",
      "          4424, 26818,   338,  6189,  1015]])}\n",
      "{'input_ids': tensor([[    1,  4013,  2022, 29915, 29879,  5046,   338, 29871, 29941, 29896,\n",
      "          7916,   338, 19361,   744,   322,  4234,   338,  3303,  3900, 29889,\n",
      "         13151,  3233,   338,  3834, 29899,  1054,  4424, 26818,   338, 11080,\n",
      "          8455,   616,   322, 17869,   338,  1090, 29871, 29945, 29900, 29968,\n",
      "          5046,   338, 29871, 29941, 29896,  7916,   338, 19361,   744,   322,\n",
      "          4234,   338,  3303,  3900, 29889, 13151,  3233,   338,  3834, 29899,\n",
      "          1054,  4424, 26818,   338, 11080]]), 'attention_mask': tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  5046,   338, 29871, 29941, 29896,\n",
      "          7916,   338, 19361,   744,   322,  4234,   338,  3303,  3900, 29889,\n",
      "         13151,  3233,   338,  3834, 29899,  1054,  4424, 26818,   338, 11080,\n",
      "          8455,   616,   322, 17869,   338,  1090, 29871, 29945, 29900, 29968,\n",
      "          5046,   338, 29871, 29941, 29896,  7916,   338, 19361,   744,   322,\n",
      "          4234,   338,  3303,  3900, 29889, 13151,  3233,   338,  3834, 29899,\n",
      "          1054,  4424, 26818,   338, 11080]])}\n",
      "{'input_ids': tensor([[    1,  4013,  2022, 29915, 29879,  5046,   338, 29871, 29906, 29941,\n",
      "          7916,   338, 27208,   322,  4234,   338,  3303,  3900, 29889, 13151,\n",
      "          3233,   338,  3834, 29899,  1054,  4424, 26818,   338,  6189,  1015,\n",
      "          8681,   312,   322, 17869,   338,  1090, 29871, 29945, 29900, 29968,\n",
      "          5046,   338, 29871, 29906, 29941,  7916,   338, 27208,   322,  4234,\n",
      "           338,  3303,  3900, 29889, 13151,  3233,   338,  3834, 29899,  1054,\n",
      "          4424, 26818,   338,  6189,  1015]]), 'attention_mask': tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  5046,   338, 29871, 29906, 29941,\n",
      "          7916,   338, 27208,   322,  4234,   338,  3303,  3900, 29889, 13151,\n",
      "          3233,   338,  3834, 29899,  1054,  4424, 26818,   338,  6189,  1015,\n",
      "          8681,   312,   322, 17869,   338,  1090, 29871, 29945, 29900, 29968,\n",
      "          5046,   338, 29871, 29906, 29941,  7916,   338, 27208,   322,  4234,\n",
      "           338,  3303,  3900, 29889, 13151,  3233,   338,  3834, 29899,  1054,\n",
      "          4424, 26818,   338,  6189,  1015]])}\n",
      "{'input_ids': tensor([[    1,  4013,  2022, 29915, 29879,  5046,   338, 29871, 29946, 29906,\n",
      "          7916,   338, 19361,   744,   322,  4234,   338,  3303,  3900, 29889,\n",
      "         13151,  3233,   338,  3834, 29899,  1054,  4424, 26818,   338, 23354,\n",
      "           292,  9427,   292,   322, 17869,   338,  1090, 29871, 29945, 29900,\n",
      "         29968,  5046,   338, 29871, 29946, 29906,  7916,   338, 19361,   744,\n",
      "           322,  4234,   338,  3303,  3900, 29889, 13151,  3233,   338,  3834,\n",
      "         29899,  1054,  4424, 26818,   338]]), 'attention_mask': tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  5046,   338, 29871, 29946, 29906,\n",
      "          7916,   338, 19361,   744,   322,  4234,   338,  3303,  3900, 29889,\n",
      "         13151,  3233,   338,  3834, 29899,  1054,  4424, 26818,   338, 23354,\n",
      "           292,  9427,   292,   322, 17869,   338,  1090, 29871, 29945, 29900,\n",
      "         29968,  5046,   338, 29871, 29946, 29906,  7916,   338, 19361,   744,\n",
      "           322,  4234,   338,  3303,  3900, 29889, 13151,  3233,   338,  3834,\n",
      "         29899,  1054,  4424, 26818,   338]])}\n",
      "{'input_ids': tensor([[    1,  4013,  2022, 29915, 29879,  5046,   338, 29871, 29945, 29955,\n",
      "          7916,   338, 27208,   322,  4234,   338,  3303,  3900, 29889, 13151,\n",
      "          3233,   338,  3834, 29899,  1054,  4424, 26818,   338,  5166,  9306,\n",
      "          5941,   414,   322, 17869,   338,  1090, 29871, 29945, 29900, 29968,\n",
      "          5046,   338, 29871, 29945, 29955,  7916,   338, 27208,   322,  4234,\n",
      "           338,  3303,  3900, 29889, 13151,  3233,   338,  3834, 29899,  1054,\n",
      "          4424, 26818,   338,  5166,  9306]]), 'attention_mask': tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  5046,   338, 29871, 29945, 29955,\n",
      "          7916,   338, 27208,   322,  4234,   338,  3303,  3900, 29889, 13151,\n",
      "          3233,   338,  3834, 29899,  1054,  4424, 26818,   338,  5166,  9306,\n",
      "          5941,   414,   322, 17869,   338,  1090, 29871, 29945, 29900, 29968,\n",
      "          5046,   338, 29871, 29945, 29955,  7916,   338, 27208,   322,  4234,\n",
      "           338,  3303,  3900, 29889, 13151,  3233,   338,  3834, 29899,  1054,\n",
      "          4424, 26818,   338,  5166,  9306]])}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleanllama/lib/python3.10/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1536\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1538\u001b[0m )\n\u001b[0;32m-> 1539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleanllama/lib/python3.10/site-packages/transformers/trainer.py:1809\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1806\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1808\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1809\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1812\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1813\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1814\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1815\u001b[0m ):\n\u001b[1;32m   1816\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1817\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/cleanllama/lib/python3.10/site-packages/transformers/trainer.py:2665\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2663\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   2664\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2665\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/miniconda3/envs/cleanllama/lib/python3.10/site-packages/accelerate/accelerator.py:1853\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1853\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleanllama/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleanllama/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleanllama/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cleanllama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
